{
 "runs":[
  {
   "tool":{
    "driver":{
     "name":"torch.onnx.dynamo_export",
     "contents":[
      "localizedData",
      "nonLocalizedData"
     ],
     "language":"en-US",
     "rules":[
      {
       "id":"FXE0010",
       "fullDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR.",
        "markdown":"This diagnostic tracks the FX passes executed during the ONNX export process prior\nto converting from FX IR (Intermediate Representation) to ONNX IR.\n\nUnder the scope of ONNX export, an FX pass refers to a specific transformation applied to the FX GraphModule.\nThe primary aim of these passes is to streamline the graph into a format that aligns more with the ONNX IR.\nMoreover, these passes work to substitute unsupported FX IR features with those recognized and endorsed by\nONNX IR. Common transformations include, but aren't limited to, decomposition, functionalization and\ntype promotion.\n\nFor those who are interested in a comprehensive log detailing the modifications made during these passes,\nthere are a couple of options:\n\n- Set DiagnosticOptions.verbosity_level to logging.DEBUG.\n- Activate the environment variable TORCH_LOGS='onnx_diagnostics'.\n\nHowever, it's noteworthy that by default, such detailed logging is turned off. The primary reason being\nits considerable impact on performance.\n\nFor an in-depth understanding of each specific pass, please refer to the directory: torch/onnx/_internal/fx/passes.\n"
       },
       "name":"fx-pass",
       "shortDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR."
       }
      }
     ],
     "version":"2.3.1+cu121"
    }
   },
   "language":"en-US",
   "newlineSequences":[
    "\r\n",
    "\n"
   ],
   "results":[
    {
     "message":{
      "markdown":"Running Decompose pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.decomp.Decompose'>\n- args: Tuple[length=1](\nTensor(i64[32, 11]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running Decompose pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running Functionalize pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.functionalization.Functionalize'>\n- args: Tuple[length=1](\nTensor(i64[32, 11]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 135, in wrapper\n    return_values = fn(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/fx/_pass.py\", line 275, in run\n    module = self._run(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/fx/passes/functionalization.py\", line 123, in _run\n    graph_module = proxy_tensor.make_fx(\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1081, in wrapped\n    t = dispatch_trace(wrap_key(func, args, fx_tracer, pre_dispatch), tracer=fx_tracer, concrete_args=tuple(phs))\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_compile.py\", line 24, in inner\n    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py\", line 451, in _fn\n    return fn(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_dynamo/external_utils.py\", line 36, in inner\n    return fn(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/fx/experimental/proxy_tensor.py\", line 541, in dispatch_trace\n    graph = tracer.trace(root, concrete_args)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py\", line 451, in _fn\n    return fn(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_dynamo/external_utils.py\", line 36, in inner\n    return fn(*args, **kwargs)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py\", line 793, in trace\n    (self.create_arg(fn(*args)),),\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/fx/experimental/proxy_tensor.py\", line 559, in wrapped\n    out = f(*tensors)\n\n  File \"<string>\", line 1, in <lambda>\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/fx/passes/functionalization.py\", line 95, in wrapped\n    pytree.tree_map(torch._sync, out)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/utils/_pytree.py\", line 900, in tree_map\n    return treespec.unflatten(map(func, *flat_args))\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/utils/_pytree.py\", line 736, in unflatten\n    leaves = list(leaves)\n\n  File \"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/_utils.py\", line 887, in _functionalize_sync\n    torch._functionalize_sync(t)  # type: ignore[attr-defined]\n\nTypeError: _functionalize_sync(): argument 't' (position 1) must be Tensor, not NoneType\n\n```",
      "text":"Running Functionalize pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/albato/.conda/envs/ml/lib/python3.9/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    }
   ]
  }
 ],
 "version":"2.1.0",
 "schemaUri":"https://docs.oasis-open.org/sarif/sarif/v2.1.0/cs01/schemas/sarif-schema-2.1.0.json"
}